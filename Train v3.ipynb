{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from numpy.random import shuffle, seed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from xfoil import XFoil\n",
    "from xfoil.model import Airfoil\n",
    "\n",
    "from lib.utils import load_pkl, save_pkl\n",
    "from config import *\n",
    "from lib.dl_modules import BatchGenerator\n",
    "from lib.preprocess_modules import interpolate_airfoil, get_alfa_step\n",
    "from nets.nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1024, 4096), (256, 1024), (512, 512)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available resolutions\n",
    "bitmap_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmap_output_number = 2\n",
    "\n",
    "# create dataset for 512x512\n",
    "pkl_folder = str(bitmap_outputs[bitmap_output_number][0])+'x'+str(bitmap_outputs[bitmap_output_number][1])\n",
    "\n",
    "# dataset config\n",
    "incl_data = { 'Cl'  : True,\n",
    "              'Cd'  : True,\n",
    "              'Cm'  : True,\n",
    "              'Cp'  : True,\n",
    "              'd'   : True,\n",
    "              'S'   : True,\n",
    "              'Re'  : False,\n",
    "              'alfa': False }\n",
    "\n",
    "# count samples amount\n",
    "samples_amount = len(os.listdir(Path(foils_bmp_path, pkl_folder)))\n",
    "samples_amount = 138\n",
    "\n",
    "# count data layers\n",
    "n_data_layers = 0\n",
    "for key in incl_data.keys():\n",
    "    if incl_data[key]: n_data_layers+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 138, layers in sample: 6.\n",
      "Taking data from 512x512 folder...\n",
      "Created empty arrays: X((138, 6, 16, 32)) and y((138, 512, 512, 1)), import data...\n",
      "Saving...\n",
      "Done.\n",
      "Totally foils in arrays: 138\n"
     ]
    }
   ],
   "source": [
    "print('Total samples: %i, layers in sample: %i.' % (samples_amount, n_data_layers))\n",
    "print('Taking data from %s folder...' % pkl_folder)\n",
    "\n",
    "X = np.zeros((samples_amount, n_data_layers, n_points_Re, n_points_alfa), dtype='float64')\n",
    "y = np.zeros((samples_amount, bitmap_outputs[bitmap_output_number][0], bitmap_outputs[bitmap_output_number][1], 1), dtype='int8')\n",
    "\n",
    "print('Created empty arrays: X(%s) and y(%s), import data...' % (X.shape, y.shape))\n",
    "\n",
    "sample = 0\n",
    "\n",
    "for fname in os.listdir(Path(foils_bmp_path, pkl_folder)): # сперва нужные профили\n",
    "    \n",
    "    if sample>samples_amount-1:break\n",
    "        \n",
    "    if fname[:2].lower() in ['ag', 'cl', 'mh', 'hq', 'hd', 'hn', 'ht' ]:        \n",
    "        foil = load_pkl(Path(foils_pkl_path, fname))        \n",
    "        ind_X=0        \n",
    "        for i, key in enumerate(incl_data):\n",
    "            if incl_data[key]:\n",
    "                X[sample, ind_X, :, :] = foil['X'][i, :, :]\n",
    "                ind_X+=1             \n",
    "        y[sample, :, :, :] = np.expand_dims(load_pkl(Path(foils_bmp_path, pkl_folder, fname)), 2)\n",
    "        sample+=1\n",
    "        \n",
    "for fname in os.listdir(Path(foils_bmp_path, pkl_folder)): #  потом все оставшиеся\n",
    "    \n",
    "    if sample>samples_amount-1:break\n",
    "        \n",
    "    if fname[:2].lower()  not in ['ag', 'cl', 'mh', 'hq', 'hd', 'hn', 'ht', 'X.', 'y.' ]:\n",
    "        \n",
    "        foil = load_pkl(Path(foils_pkl_path, fname))\n",
    "        \n",
    "        ind_X=0\n",
    "        \n",
    "        for i, key in enumerate(incl_data):\n",
    "            if incl_data[key]:\n",
    "                X[sample, ind_X, :, :] = foil['X'][i, :, :]\n",
    "                ind_X+=1   \n",
    "        y[sample, :, :, :] = np.expand_dims(load_pkl(Path(foils_bmp_path, pkl_folder, fname)), 2)\n",
    "        sample+=1\n",
    "        \n",
    "# reshaping X \n",
    "X = X.reshape(samples_amount, n_data_layers*n_points_Re*n_points_alfa)\n",
    "\n",
    "assert np.sum(np.isnan(X))==0, \"NaNs in X\"\n",
    "assert np.sum(np.isnan(y))==0, \"NaNs in y\"\n",
    "\n",
    "print('Saving...')\n",
    "\n",
    "save_pkl(X, Path(dataset_folder, \"X.pkl\"))\n",
    "save_pkl(y, Path(dataset_folder, \"y.pkl\"))\n",
    "\n",
    "del X, y\n",
    "gc.collect()\n",
    "\n",
    "print('Done.')\n",
    "print(\"Totally foils in arrays: %i\" % (sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138, 3072), (138, 512, 512, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_pkl(Path(dataset_folder, 'X.pkl'))\n",
    "y = load_pkl(Path(dataset_folder, 'y.pkl'))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(len(X))\n",
    "seed(42)\n",
    "shuffle(all_indices)\n",
    "\n",
    "n_indices = len(X)\n",
    "train_part = int(n_indices*train_percentage)\n",
    "val_part = int(n_indices*val_percentage)\n",
    "train_part, val_part\n",
    "train_indices = all_indices[:train_part]\n",
    "val_indices = all_indices[train_part:val_part]\n",
    "test_indices = all_indices[val_part:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light parametrization net output shape: (None, 512, 512, 1)\n",
      "Epoch 1/1000\n",
      "103/103 [==============================] - 9s 87ms/step - loss: 0.1660 - mse: 0.1660 - val_loss: 0.1450 - val_mse: 0.1450\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 8s 82ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 9s 84ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0099 - val_mse: 0.0099- loss: 0.0154 - mse: 0 - ETA: 5s - lo - ETA: 4s - loss: 0.\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 9s 83ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0093 - val_mse: 0.00930.0063 - mse: 0.0 - ETA: 1s - loss:\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 8s 82ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0129 - val_mse: 0.0129 0s - loss: 0.0058 - ms\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 9s 86ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0083 - val_mse: 0.0083 ms\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0077 - val_mse: 0.0077- loss:\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0100 - val_mse: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0094 - val_mse: 0.00941s - loss: 0.0055 - m - ETA: 0s - loss: 0.0056 \n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 8s 82ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 69/1000\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.0051 - mse: 0.0051- ETA: 1s - loss\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 99/1000\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.0038 - mse: 0.003 - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0099 - val_mse: 0.0099: 0.0033 - mse - ETA: 1s - loss: 0.0\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0100 - val_mse: 0.0100: 0.0030 - mse: 0\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 8s 80ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0109 - val_mse: 0.0109s - loss: 0.0027 - ms\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0113 - val_mse: 0.0113s - loss: 0.0026\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0109 - val_mse: 0.0109s - loss: - ETA: 4s - loss: 0.0 - ETA: 3s - - ETA: 1s - loss: 0.0028 - mse: 0.00 - ETA: 1s - loss: 0.0027 - ms - ETA: 0s - loss: 0.0027 - ms\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 139/1000\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.0026 - mse: 0.0026- ETA: 0s - loss: 0.0026 - mse: 0\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 8s 78ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 8s 81ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 8s 79ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 9s 87ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 152/1000\n",
      " 86/103 [========================>.....] - ETA: 1s - loss: 0.0023 - mse: 0.0023"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-99d08bf27de9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m history = model.fit_generator(generator=train_generator, validation_data=val_generator, \n\u001b[0;32m     24\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_reduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#, m_save],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                              verbose=1, workers=1, use_multiprocessing=False)\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# save history and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    525\u001b[0m       \u001b[0mvariance\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m     \u001b[0mtraining_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m       momentum = tf_utils.smart_cond(training,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msmart_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_constant_value\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m     73\u001b[0m   \"\"\"\n\u001b[0;32m     74\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;31m# TODO(skyewm): consider folding this into tensor_util.constant_value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    790\u001b[0m   \"\"\"\n\u001b[0;32m    791\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\p374\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrepresentable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     \"\"\"\n\u001b[1;32m--> 933\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs=1000\n",
    "batch_size=1\n",
    "lr=1e-3\n",
    "reg=0.001\n",
    "\n",
    "model = light_param_net(X.shape[1], reg=reg, learning_rate=lr)\n",
    "# model = flexi_net(input_vector_size=X.shape[1], output_size=y[0,:,:,0].shape, reg=reg, learning_rate=lr)\n",
    "# model.load_weights(str(Path(\"./weights\", r_name+'.h5')))#'initial_weights_300foils_04122020.h5')))\n",
    "\n",
    "# data generators\n",
    "train_generator = BatchGenerator(X, y, train_indices, batch_size=batch_size, Xdim=X[0].shape, ydim=y[0].shape)\n",
    "val_generator   = BatchGenerator(X, y, val_indices, batch_size=batch_size, Xdim=X[0].shape, ydim=y[0].shape)\n",
    "test_generator  = BatchGenerator(X, y, test_indices, batch_size=1, Xdim=X[0].shape, ydim=y[0].shape, shuffle=False)\n",
    "\n",
    "# callbacks\n",
    "early_stop = EarlyStopping(monitor='loss', patience=30, restore_best_weights=True, verbose=1)\n",
    "lr_reduce  = ReduceLROnPlateau(monitor='loss', min_lr=0, cooldown=10, factor=0.2, patience=10, verbose=1, mode='min')\n",
    "# lr_reduce = CosineLR(min_lr=1e-12, max_lr=lr, steps_per_epoch=np.ceil(len(train_indices)/batch_size), lr_decay=0.9)\n",
    "# m_save = ModelCheckpoint(str(Path(results_path, 'weights', 'temp_weights.h5')), monitor='val_mse', \n",
    "#                          verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
    "\n",
    "# train model\n",
    "history = model.fit_generator(generator=train_generator, validation_data=val_generator, \n",
    "                             epochs=n_epochs, callbacks=[early_stop, lr_reduce],#, m_save],                              \n",
    "                             verbose=1, workers=1, use_multiprocessing=False)\n",
    "\n",
    "# save history and weights\n",
    "# r_name = (str(datetime.now())[:16]).replace(':','-')\n",
    "# unet.save_weights(str(Path(results_path,'weights', r_name+'.h5')))\n",
    "# save_pkl(history.history, Path(results_path,'weights', r_name+'.pkl'))\n",
    "\n",
    "print('Done.')\n",
    "print(\"Val_loss: %2.4e\" % np.min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save history and weights\n",
    "# from datetime import datetime\n",
    "# r_name = (str(datetime.now())[:16]).replace(':','-')\n",
    "# model.save_weights(str(Path(weights_path, r_name+'.h5')))\n",
    "# save_pkl(history.history, Path(weights_path, r_name+'.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512x512\n",
    "138:\n",
    "16: Val_loss: 2.1742e-03\n",
    "8: Val_loss: 1.6951e-03\n",
    "4: Val_loss: 2.0985e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(str(Path(\"./weights\", '2020-12-25 10-16.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(Path(\"./weights\", '512x512.h5'),include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249af6350c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = test_generator[10]\n",
    "X_test = np.expand_dims(X_test[0], 0)\n",
    "y_test = np.expand_dims(y_test[0], 0)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.matshow(y_test[0,:,:,0],0)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow((np.round(y_pred[0,:,:,0])-y_test[0,:,:,0]),0)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.matshow(y_pred[0,:,:,0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d5d818a48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.round(y_pred)[0, :, :, 0]\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.matshow(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 257, 486)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ищем координаты\n",
    "\n",
    "# сначала определим координаты начала и конца оси профиля\n",
    "\n",
    "for x_nose in range(y.shape[1]):\n",
    "    res = find_first_and_last_1_position(y[:, x_nose])\n",
    "    if res!=-1:\n",
    "        y_nose_top, y_nose_bot = res\n",
    "        break\n",
    "        \n",
    "for x_tail in range(y.shape[1]-1,0,-1):\n",
    "    res = find_first_and_last_1_position(y[:, x_tail])\n",
    "    if res!=-1:\n",
    "        y_tail_top, y_tail_bot = res\n",
    "        break\n",
    "\n",
    "if y_nose_top!=y_nose_bot: # ставим точку в середине носика, пригодится для красивой аппроксимации\n",
    "    y_nose = int(np.average((y_nose_top, y_nose_bot)))\n",
    "    y[y_nose,x_nose-1]=1\n",
    "    x_nose-=1\n",
    "\n",
    "if y_tail_top!=y_tail_bot: # а на хвостике не ставим и вообще хз чё делаем - к Димке\n",
    "    pass\n",
    "#     y_tail = int(np.average((y_tail_top, y_tail_bot)))\n",
    "# else:\n",
    "#     y_tail = y_tail_top\n",
    "    \n",
    "x_nose, y_nose, x_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d5d881a08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.matshow(y[:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foil_x_top = (np.arange(y.shape[1])).tolist(); foil_x_top.reverse()\n",
    "foil_x_bot = foil_x_top.copy() #foil_x[:-1]; x2.reverse() ; foil_x.extend(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "foil_y_top=[]\n",
    "foil_y_bot=[]\n",
    "for x in foil_x_top:\n",
    "    if find_first_and_last_1_position(y[:, x])==-1: raise Exception\n",
    "    y_t, y_b = find_first_and_last_1_position(y[:, x])\n",
    "    foil_y_top.append(y_nose - y_t)\n",
    "    foil_y_bot.append(y_nose - y_b)\n",
    "foil_x_bot = foil_x_bot[:-1]\n",
    "foil_x_bot.reverse()\n",
    "foil_y_bot = foil_y_bot[:-1]\n",
    "foil_y_bot.reverse()\n",
    "foil_x_top.extend(foil_x_bot)\n",
    "foil_y_top.extend(foil_y_bot)\n",
    "foil_x = np.array(foil_x_top)/(y.shape[1]-1)\n",
    "foil_y = np.array(foil_y_top)/(y.shape[1]-1)\n",
    "foil_x.shape, foil_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,3),  frameon=False)\n",
    "canvas = FigureCanvasAgg(fig)\n",
    "ax = fig.add_axes([0.,0.,1.,1.])\n",
    "ax.fill(foil_x, foil_y, 'black')\n",
    "ax.axis('equal');\n",
    "ax.axis('off');\n",
    "s, (width, height) = canvas.print_to_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x, f_y = interpolate_airfoil(foil_x, foil_y, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3bacc078521e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mxf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfa_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malfa_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malfa_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set list of Re's\n",
    "Re = np.linspace(re_min, re_max, n_points_Re).astype(int)\n",
    "# get list of alfas and alfa step\n",
    "alfa_step, alfas = get_alfa_step(alfa_min, alfa_max, n_points_alfa)\n",
    "\n",
    "current_foil = Airfoil(f_x, f_y)\n",
    "xf = XFoil()\n",
    "xf.airfoil = current_foil\n",
    "xf.max_iter = xfoil_max_iterations\n",
    "for num in range(16):\n",
    "\n",
    "    xf.Re = Re[num]        \n",
    "    a, cl, cd, cm, cp = xf.aseq(alfa_min, alfa_max, alfa_step)\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02837718, 0.02839214,        nan, 0.02836622, 0.02817133,\n",
       "       0.02833435, 0.02826537, 0.02814429,        nan, 0.02774858,\n",
       "       0.02756903, 0.02694843, 0.02696838, 0.02691632, 0.02691655,\n",
       "       0.02713087, 0.02756391, 0.02802133, 0.02832558, 0.02898849,\n",
       "       0.02910685, 0.03026072, 0.0305083 , 0.03105625, 0.03270565,\n",
       "       0.0311233 , 0.0314392 , 0.03160494, 0.03249761, 0.03365809,\n",
       "       0.03503241, 0.03579408])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6468ceae391a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXFoil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Oleg\\miniconda3\\envs\\tf200\\lib\\site-packages\\xfoil\\xfoil.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mcopy2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_airfoil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Oleg\\miniconda3\\envs\\tf200\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Oleg\\miniconda3\\envs\\tf200\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "xf = XFoil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'config' has no attribute 'Re'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2e99ee927d8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'config' has no attribute 'Re'"
     ]
    }
   ],
   "source": [
    "config.Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  9.78822842e-01,  9.56628964e-01,  9.34466611e-01,\n",
       "        9.11833094e-01,  8.89197903e-01,  8.65163451e-01,  8.43471751e-01,\n",
       "        8.20380303e-01,  7.97399321e-01,  7.73751246e-01,  7.51108000e-01,\n",
       "        7.28928454e-01,  7.04979917e-01,  6.81836347e-01,  6.57839994e-01,\n",
       "        6.34746949e-01,  6.11204402e-01,  5.87628664e-01,  5.64092901e-01,\n",
       "        5.40558285e-01,  5.16556265e-01,  4.92554244e-01,  4.69463582e-01,\n",
       "        4.45473249e-01,  4.21003857e-01,  3.96546143e-01,  3.73927724e-01,\n",
       "        3.50364841e-01,  3.27732220e-01,  3.03727829e-01,  2.80181480e-01,\n",
       "        2.56635184e-01,  2.33090633e-01,  2.09540389e-01,  1.85995122e-01,\n",
       "        1.62905375e-01,  1.40270285e-01,  1.18092448e-01,  9.81206170e-02,\n",
       "        7.50923075e-02,  5.48236153e-02,  3.34411074e-02,  1.24792319e-02,\n",
       "       -9.65488169e-04, -3.81271181e-03, -1.58921242e-03,  5.41915016e-03,\n",
       "        1.69265161e-02,  3.26470255e-02,  5.22948185e-02,  7.55840352e-02,\n",
       "        1.02228816e-01,  1.31943301e-01,  1.64441630e-01,  1.99437943e-01,\n",
       "        2.36646381e-01,  2.75781083e-01,  3.16556190e-01,  3.58685842e-01,\n",
       "        4.01884180e-01,  4.45865342e-01,  4.90343470e-01,  5.35032703e-01,\n",
       "        5.79647182e-01,  6.23901047e-01,  6.67508438e-01,  7.10183494e-01,\n",
       "        7.51640357e-01,  7.91593167e-01,  8.29756063e-01,  8.65843185e-01,\n",
       "        8.99568675e-01,  9.30646671e-01,  9.58791315e-01,  9.83716745e-01,\n",
       "        1.00513710e+00,  1.02276653e+00,  1.03631916e+00,  1.04550914e+00,\n",
       "        1.05005061e+00,  1.04965771e+00,  1.04404458e+00,  1.03292535e+00,\n",
       "        1.01601417e+00,  9.93243458e-01,  9.69241359e-01,  9.46150774e-01,\n",
       "        9.22583133e-01,  8.98601703e-01,  8.75502084e-01,  8.53769356e-01,\n",
       "        8.29330426e-01,  8.04872724e-01,  7.80872381e-01,  7.56868679e-01,\n",
       "        7.32826767e-01,  7.08408954e-01,  6.83951162e-01,  6.59950788e-01,\n",
       "        6.36259158e-01,  6.11945075e-01,  5.88854523e-01,  5.65018320e-01,\n",
       "        5.41306159e-01,  5.17842460e-01,  4.95126773e-01,  4.72034176e-01,\n",
       "        4.49435491e-01,  4.26310584e-01,  4.02306511e-01,  3.78759369e-01,\n",
       "        3.54758147e-01,  3.30300445e-01,  3.06298432e-01,  2.81840720e-01,\n",
       "        2.57736249e-01,  2.33836675e-01,  2.09834121e-01,  1.85377486e-01,\n",
       "        1.62286249e-01,  1.37836300e-01,  1.15649301e-01,  9.16178541e-02,\n",
       "        6.90110856e-02,  4.50102371e-02,  2.19309051e-02,  1.10011001e-03])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([a,b]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xo = x.copy()\n",
    "xo.reverse()\n",
    "xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.extend(xo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 3, 2, 1]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(y[:,49]), y[:,49].shape)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
